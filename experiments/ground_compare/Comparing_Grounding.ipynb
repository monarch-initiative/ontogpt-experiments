{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38282fe7-41ee-4400-8c5b-cd6b87d53a1c",
   "metadata": {},
   "source": [
    "# Comparing Grounding between OntoGPT and GPT Alone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766fd228-7242-49b7-918b-091ac5b67cc2",
   "metadata": {},
   "source": [
    "This notebook performs the following:\n",
    "* Installs dependencies, primarily ontogpt\n",
    "* Retrieves all identifiers and terms for a specified ontology\n",
    "* Prepares a randomly-determined selection of 100 term descriptions\n",
    "* Attempts to ground all terms in the selection with OntoGPT and a template specific to the ontology\n",
    "* Attempts to ground all terms in the selection through a text completion query sent to GPT-3.5-turbo and GPT-4-turbo\n",
    "\n",
    "This notebook is intended to be run with Python 3.9 on a *nix-like system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fc6829-6c5c-43e3-8348-ec1610c2f57c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed7b544-d980-4f96-8723-ebdea7acba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ontogpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf521dd8-75ff-4e78-b552-b18dd4c86d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import linecache\n",
    "import random\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2255d129-9f86-4512-a4eb-ebacbb30b456",
   "metadata": {},
   "source": [
    "The following variable will set the ontology name. It should be lowercase and be in the OBO Foundry, e.g., \"caro\" or \"envo\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bbee4a-a2af-4c47-8892-96b1127bfce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_name = \"mondo\"\n",
    "termfile = f\"{onto_name}_terms.tsv\"\n",
    "select_termfile = f\"{onto_name}_terms_select.tsv\"\n",
    "extract_file_35 = f\"{onto_name}_extract_35.yaml\"\n",
    "extract_file_4 = f\"{onto_name}_extract_4.yaml\"\n",
    "prompting_file = f\"{onto_name}_prompt.txt\"\n",
    "prompt_extract_file_35 = f\"{onto_name}_prompt_extract_35.txt\"\n",
    "prompt_extract_file_4 = f\"{onto_name}_prompt_extract_4.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc63767-d018-417f-949f-dcb61f2e07d3",
   "metadata": {},
   "source": [
    "Now we retrieve all terms. Note that this will exclude obsolete terms by default. It may take a moment to complete this for larger ontologies.\n",
    "\n",
    "Then we filter that to a list of 100 randomly-selected identifiers and terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de300d20-811e-46ad-a985-6de61d9732b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!runoak -i sqlite:obo:{onto_name} terms > {termfile}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d2a25d-520b-4287-aebd-0b71f1fddeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_count = 100\n",
    "i = 0\n",
    "term_map = {}\n",
    "with open(termfile) as infile:\n",
    "    linecount = sum(1 for line in infile)\n",
    "while i < desired_count:\n",
    "    oneterm = linecache.getline(termfile, random.randrange(0,linecount)).rstrip()\n",
    "    if (oneterm.lower()).startswith(onto_name):\n",
    "        split_term = oneterm.split(\"!\")\n",
    "        curie = split_term[0].strip()\n",
    "        label = split_term[1].strip()\n",
    "        term_map[curie] = label\n",
    "        i = i +1\n",
    "\n",
    "len(term_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1a9761-719f-4da7-af75-4246011beb03",
   "metadata": {},
   "source": [
    "## Grounding with OntoGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f29bcb-0334-435b-9e9b-64e0e0aa856f",
   "metadata": {},
   "source": [
    "We assemble a document of _terms alone_ to parse with OntoGPT and SPIRES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d365e928-8091-4f70-b511-93cacba9592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(select_termfile, \"w\") as outfile:\n",
    "    for label in term_map.values():\n",
    "        outfile.write(f\"{label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f36a52f-4fdf-4a50-b31a-25afc3ecbd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses the gpt-3.5-turbo-16k model.\n",
    "!ontogpt -vvv extract -i {select_termfile} -t {onto_name}_simple -o {extract_file_35} -m gpt-3.5-turbo-16k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3c5bc1-d61f-470b-a58b-f1a53f2b591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses the gpt-4-turbo model (as gpt-4-1106-preview)\n",
    "!ontogpt -vvv extract -i {select_termfile} -t {onto_name}_simple -o {extract_file_4} -m gpt-4-1106-preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd89bc76-2ab3-4580-8010-e7aa55d08d3b",
   "metadata": {},
   "source": [
    "Now we parse the results and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa557c-11db-4242-9b50-42b6fc767501",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in [extract_file_35, extract_file_4]:\n",
    "    score = 0\n",
    "    with open(filename) as infile:\n",
    "        print(f\"*** {filename} ***\")\n",
    "        extract = yaml.safe_load(infile)\n",
    "        named_entities = extract[\"named_entities\"]\n",
    "        print(f\"Total named entities found: {len(named_entities)}\")\n",
    "        for curie in term_map:\n",
    "            term_pair = {'id':curie, 'label':term_map[curie]}\n",
    "            if term_pair in named_entities:\n",
    "                score = score + 1\n",
    "        pct_score = float(score / len(term_map))\n",
    "        print(f\"Total score: {score} / {len(term_map)} ({pct_score})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b406567-d59d-4862-a203-8d355a46bb1d",
   "metadata": {},
   "source": [
    "## Grounding with GPT alone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84803a0-7de4-49d2-8582-c3dae517457e",
   "metadata": {},
   "source": [
    "Now we repeat the process, passing the same selected term list to GPT through the OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4a5fb-5515-4d18-8c82-fb1334f36b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the prompt for GPT-3+. We assemble this and the terms into a file.\n",
    "inprompt = f\"Please provide the corresponding identifier from the {onto_name} Ontology for each of the following terms. The output should be in the following format: \\n id: IDENTIFIER ! label: LABEL \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c33f72-8a18-40d7-92da-9b0e11db1733",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(prompting_file, \"w\") as outfile:\n",
    "    outfile.write(inprompt)\n",
    "    for label in term_map.values():\n",
    "        outfile.write(f\"{label}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66028835-ac14-43bb-b6c8-84a997ef9cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses the gpt-3.5-turbo-16k model.\n",
    "!ontogpt -vvv complete -o {prompt_extract_file_35} -m gpt-3.5-turbo-16k {prompting_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba303b7-4da7-41c7-936b-23002d2e4121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses the gpt-4-turbo model (as gpt-4-1106-preview)\n",
    "!ontogpt -vvv complete -o {prompt_extract_file_4} -m gpt-4-1106-preview {prompting_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccdc773-0f83-4e59-8972-1ac68ff1cdb7",
   "metadata": {},
   "source": [
    "And now we score it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86c8486-9085-453b-8b69-16c286415fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in [prompt_extract_file_35, prompt_extract_file_4]:\n",
    "    score = 0\n",
    "    named_entities = []\n",
    "    with open(filename) as infile:\n",
    "        print(f\"*** {filename} ***\")\n",
    "        for line in infile:\n",
    "            if not line.startswith(\"id\"):\n",
    "                continue\n",
    "            else:\n",
    "                try:\n",
    "                    splitline = line.split(\"!\")\n",
    "                    id = (splitline[0].split(\"id:\"))[1].strip()\n",
    "                    label = (splitline[1].split(\"label:\"))[1].strip()\n",
    "                    pair = {\"id\": id, \"label\": label}\n",
    "                    named_entities.append(pair)\n",
    "                except IndexError:\n",
    "                    continue\n",
    "        print(f\"Total named entities found: {len(named_entities)}\")\n",
    "        for curie in term_map:\n",
    "            term_pair = {'id':curie, 'label':term_map[curie]}\n",
    "            if term_pair in named_entities:\n",
    "                score = score + 1\n",
    "        pct_score = float(score / len(term_map))\n",
    "        print(f\"Total score: {score} / {len(term_map)} ({pct_score})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
